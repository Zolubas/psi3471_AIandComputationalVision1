{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSI3471 - Entrega 01 \n",
    "### Fernando Zolubas Preto - NUSP: 10694192\n",
    "### Vinícius Melo de Souza - NUSP: 10772272\n",
    "# Regressão Linear "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exercício queremos prever o preço de carros do _\"Used Cars Dataset\"_ do site `Craiglist.org`.\n",
    "\n",
    "No caso, os dados já foram limpos e filtrados para facilitar o entendimento e o andamento do exercício, para conseguirmos dar foco na utilização da técnica dos mínimos quadrados. Os dados limpos estão em um arquivo CSV que podemos puxar do site da disciplina. Este arquivo será importado através da biblioteca \"Panda\" do python que foi instalada no computador previamente.\n",
    "\n",
    "Com esses dados, queremos criar um _\"DataFrame\"_ que estaremos chamando de __cars_data__, que irá conter esses dados do arquivo CSV. Neste _DataFrame_ estaremos gerando os arrays NumPy para calcular os parâmetros do modelo de regressão linear.\n",
    "\n",
    "Temos essas 9 colunas que se referem à:\n",
    "\n",
    "- __Price__: O preço do carro. É o dado que desejamos obter com o modelo.\n",
    "- __Year__: Ano do carro.\n",
    "- __Condition__: Variável categórica que indica a condição do carro. Pode ter os valores _good_, _fair_, _excellent_, _like new_, _salvage_, ou _new_.\n",
    "- __Cylinders__: Variável categórica que indica o número de cilindros do motor. Pode ter os valores _4 cylinders_ ou _6 cylinders_.\n",
    "- __Fuel__: Variável categórica que indica o combustível do carro. Pode ter os valores _gas_ ou _diesel_.\n",
    "- __Odometer__: Valor registrado no odômetro, em milhas.\n",
    "- __Transmission__: Variável categórica que indica o tipo de transmissão. Pode ter os valores _automatic_ ou _manual_.\n",
    "- __Size__: Variável categórica que indica o tamanho do carro. Pode ter os valores _compact_, _mid-size_, _sub-compact_ ou _full-size_.\n",
    "- __Type__:\tVariável categórica que indica o tipo do carro. Pode ter os valores _sedan_, _coupe_, _wagon_, ou _hatchback_.\n",
    "\n",
    "\n",
    "Para usar os dados categóricos de forma numérica iremos estar utilizando variáveis _dummy_.\n",
    "\n",
    "E por fim, para obter o vetor \"wo\" vamos seguir os seguintes passos.\n",
    "\n",
    "1. Selecionar o conjunto de variáveis originais que vocễ vai utilizar no modelo.\n",
    "2. Substituir cada variável categórica de sua seleção por um conjunto de variáveis dummy, conforme descrito anteriormente.\n",
    "3. Transformar as variáveis originais de sua seleção e / ou incluir combinações, caso julgue necessário;\n",
    "4. A partir de sua seleção de dados, obter a matriz X e o vetor d, que podem ser representados como arrays do NumPy.\n",
    "5. Usando a matriz X e o vetor d, calcular o vetor wo e o erro quadrático médio conforme mostrado na aula.\n",
    "\n",
    "# Nossa solução\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Buscando a regressão linear limpando a base e tratando problemas com os dados "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Obtenção dos da base de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando os data frames de treino e de teste a partir dos arquivos CSV \"limpos\" extraídos da base de dados _\"Used Cars Dataset\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data = pd.read_csv(\"vehicles_cleaned_train.csv\")\n",
    "cars_data_teste = pd.read_csv(\"vehicles_cleaned_test.csv\")\n",
    "\n",
    "colNames_cars_data = cars_data.columns.tolist()\n",
    "colNames_cars_data_teste = cars_data_teste.columns.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Análise preliminar da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data_teste.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As dimensões da base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Numero de Linhhas, Numero de Colunas) = \", cars_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As dimensões da base de teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Numero de Linhhas, Numero de Colunas) = \", cars_data_teste.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como Esperado existem mais dados na base de treinamento, 8338, do que na base de teste, 2084."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPercentage = 100.0*cars_data.shape[0]/(cars_data.shape[0] + cars_data_teste.shape[0])\n",
    "print(\"Porcentagem de dados de teste em relação aos dados totais disponiveis = \",testPercentage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proporção dos dados disponíveis dividem-se em 80% para treino e 20% para teste. Algo prróximo da relação padrão 70/30 comumente utilizada. Logo a proporção considerada faz sentido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir faremos um teste final de verificação para checar se de fato a matriz de Treinamento e a matriz de Testes não possuem veículos em comum, isto é, se de fato não há um viés de treinamento do tipo _overfitting_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_identical_rows(matrix1, matrix2):\n",
    "    for row1 in matrix1:\n",
    "        for row2 in matrix2:\n",
    "            if np.array_equal(row1, row2):\n",
    "                print(row1)\n",
    "                print(row2)\n",
    "                return True    \n",
    "    return False\n",
    "\n",
    "matrizTreinamento = cars_data.to_numpy()\n",
    "matrizTreinamentoTeste = cars_data_teste.to_numpy()\n",
    "\n",
    "if check_identical_rows(matrizTreinamento,matrizTreinamentoTeste):\n",
    "    print(\"matriz de Teste Inadequada\")\n",
    "else:\n",
    "    print(\"Matriz de Teste Adequada\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que há ao menos um dado da base de testes identico a um dado da base de treinamento. Sendo assim, uma limpeza adicional nos dados de teste será necessária antes de se prosseguir com a análise de modo que a \"validação\" feita na base de testes esteja pouco sujeita ao viés do tipo _overfitting_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Limpeza das matriz de Teste e de Treinamento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rotina a seguir verifica se as Matriz de Treinamento e de Teste apresentam elementos em comum ou não. A matriz de teste será considerada **ADEQUADA** se e somente se não possuir dados em comum, isto é, linhas em comum com a matriz de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_identical_rows(matrix1, matrix2):\n",
    "    to_delete = []\n",
    "    for i, row1 in enumerate(matrix1):\n",
    "        for j, row2 in enumerate(matrix2):\n",
    "            if np.array_equal(row1, row2):\n",
    "                to_delete.append(j)\n",
    "    new_matrix = np.delete(matrix2, np.unique(to_delete), axis=0)\n",
    "    return new_matrix\n",
    "\n",
    "novaMatrizTreinamentoTeste = delete_identical_rows(matrizTreinamento,matrizTreinamentoTeste)\n",
    "\n",
    "if check_identical_rows(matrizTreinamento,novaMatrizTreinamentoTeste):\n",
    "    print(\"matriz de Teste Inadequada\")\n",
    "else:\n",
    "    print(\"Matriz de Teste Adequada\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de treinamento é adequada como se vê na verificação realizada acima. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato, vemos a seguir que hove uma redução de linhas de 2084 para 1486. Isso agilizará o processo de validação da regressão via matriz de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novaMatrizTreinamentoTeste.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém, procurando-se manualmente a linha repetida \n",
    "\n",
    "[9400 2013 'good' '4 cylinders' 'gas' 78980 'automatic' 'full-size'\n",
    " 'coupe']\n",
    "\n",
    "percebeu-se que a base de treinamento possui multiplas ocorrências do mesmo dado. Dado que o mesmo pode ocorrer para a matriz de teste reliza-se a eliminação dos dados repetidos para que os cálculos posteriores sejam mais eficientes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método ```.drop_duplicates()``` é utilizado nas matrizes do tipo np.array dtype transformadas em dataFrames por meio de ```pd.DataFrame`()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data_clean = pd.DataFrame(matrizTreinamento)\n",
    "cars_data_teste_clean = pd.DataFrame(novaMatrizTreinamentoTeste)\n",
    "\n",
    "print(\"Dimensoes do data frame de treinamento ANTES da eliminação de dulplicidade de linhas = \",cars_data_clean.shape)\n",
    "print(\"Dimensoes do data frame de testes ANTES da eliminação de dulplicidade de linhas = \",cars_data_teste_clean.shape)\n",
    "\n",
    "cars_data_clean = cars_data_clean.drop_duplicates()\n",
    "cars_data_teste_clean = cars_data_teste_clean.drop_duplicates()\n",
    "\n",
    "print(\"Dimensoes do data frame de treinamento DEPOIS da eliminação de dulplicidade de linhas = \",cars_data_clean.shape)\n",
    "print(\"Dimensoes do data frame de testes DEPOIS da eliminação de dulplicidade de linhas = \",cars_data_teste_clean.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, eliminam-se repitções na base de treinamentos e de testes. Observe que o número de dados de treinamento foi reduzido de 8338 para 6836. O número de dados de teste foi reduzido de 1486 para 1443.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_identical_rows(cars_data_clean.to_numpy(),cars_data_teste_clean.to_numpy()):\n",
    "    print(\"matriz de Teste Inadequada\")\n",
    "else:\n",
    "    print(\"Matriz de Teste Adequada\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho de código a seguir recupera os nomes das colunas dos dataframes que foram peridos devido a conversão de data frame para numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data_clean.columns = colNames_cars_data\n",
    "cars_data_teste_clean.columns = colNames_cars_data_teste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a eliminação de duplicidades de linhas uma última checagem é feita e de fato, a partir desse momento, tem-se uma base de treinamento independente da base de testes, isto é, as dudas bases de dado não compartilham dados, isto é, linhas entre sí."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Criação de Variáveis Dummy como substituição de variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando variaveis categóricas e transformando em 'Dummy' para o DataFrame de treino e de teste\n",
    "categorical_columns = ['condition', 'cylinders', 'fuel', 'transmission', 'size', 'type']\n",
    "\n",
    "# Treino\n",
    "X_train = pd.get_dummies(cars_data_clean[categorical_columns])\n",
    "X_train['fabrication'] = cars_data_clean['year']\n",
    "X_train['odometer'] = cars_data_clean['odometer']\n",
    "\n",
    "d_train = cars_data_clean['price']\n",
    "\n",
    "# Teste\n",
    "X_test = pd.get_dummies(cars_data_teste_clean[categorical_columns])\n",
    "X_test['fabrication'] = cars_data_teste_clean['year']\n",
    "X_test['odometer'] = cars_data_teste_clean['odometer']\n",
    "\n",
    "d_test = cars_data_teste_clean['price']\n",
    "\n",
    "\n",
    "# Criando nossas variáveis para o DataFrame de treino e de teste\n",
    "current_year = 2023\n",
    "X_train['age'] = current_year - X_train['fabrication'] # Variável de 'idade' do carro\n",
    "X_train['mileage_per_year'] = X_train['odometer'] / X_train['age'] # Variável de 'milhagem/idade' do carro\n",
    "\n",
    "X_test['age'] = current_year - X_test['fabrication'] # Variável de 'idade' do carro\n",
    "X_test['mileage_per_year'] = X_test['odometer'] / X_test['age'] # Variável de 'milhagem/idade' do carro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Análise de Linearidade dos dados vs variável objetivo\n",
    "\n",
    "A ideia dessa seção é analisar se há uma relação linar entre o preço dos veículos e as variáveis a serem consideradas. Com base nessa análise, poderemos saber se é esperado que a regressão linear forneça bons resultados de previsão do valor dos veículos ou não. A análise pode ser feita de maneira univariada pois em caso das relações serem lineares pode-se utilizar o princípio da superposição para intuir que a regressão linear será um bom modelo nesse caso.\n",
    "\n",
    "Se for complicado determinar a linearidade da relação, o objetivo será ao menos determinar se existe alguma relação entre o preço e uma variável disponível na base. Isto é, a ida é verificar se o preço se altera de uma maneira expressiva com a mudança de cada variável da base.\n",
    "\n",
    "O cabeçalho contendo as variáveis originais da base é mostrado a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a seguir a relação entre o preço e as variávies originais da base de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_columns(df, x_col, y_col, title=''):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(df[x_col], df[y_col], label=y_col)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot = plot_columns(cars_data_clean, 'year', 'price', 'Price per year')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o ano influência de forma crescente no preço do carro. Qualitativamente, é notório que o valor médio dos veículos aumenta na medida em que o veículo considerado é mais novo, isto é, é de um ano mais recente. Conclusão: O ano do carro parece ser importante para inferir o seu preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_columns(cars_data_clean, 'condition', 'price', 'Price per condition')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que a condição do veículo influência de forma crescente no preço do carro. Qualitativamente, é notório que o valor médio dos veículos aumenta na medida em que o veículo considerado em melhor estado, isto é, o preço de um veículo _excellent_ tende a ser maior do que de um veículo _fair_ . Conclusão: A condição do carro parece ser importante para inferir o seu preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_columns(cars_data_clean, 'cylinders', 'price', 'Price per cylinders')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o número de cilindros somente não é um parâmetro determinador do preço mesmo que talvez essa possa ser uma característica relevante para determinar esse valor. Conclusão: O número de cilindros do carro não parece ser tão importante isoladamente para inferir o seu preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_columns(cars_data_clean, 'fuel', 'price', 'Price per fuel')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o tipo de combustível do veículo influência de forma crescente no preço do carro. Qualitativamente, é possível ver que os veículos movidos a disel não serão nem os mais baratos e nem os mais caros. Conclusão: O típo de combustível do carro parece ser importante para inferir o seu preço ainda que o tipo sozinho não forneça uma indicação muito precisa sobre isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_columns(cars_data_clean, 'odometer', 'price', 'Price per odometer')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o odometro do veículo influência de forma decrescente no preço do carro. Qualitativamente, é possível ver que os veículos com maior leitura do odômetro tendem a custar menos (vide faixa azul opaca decrescente). Conclusão: O odometro do carro parece ser importante para inferir o seu preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_columns(cars_data_clean, 'transmission', 'price', 'Price per transmission')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão: O tipo de transmissão do carro parece ser pouco importante para inferir o seu preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_columns(cars_data_clean, 'size', 'price', 'Price per size')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão: O tamanho do carro parece ser pouco importante para inferir o seu preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_columns(cars_data_clean, 'type', 'price', 'Price per type')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão: O tipo do carro parece ser pouco importante para inferir o seu preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL(d, d_teste, combination, combination_teste):\n",
    "\n",
    "    #d = d.astype('int64')\n",
    "    #d_teste = d_teste.astype('int64')\n",
    "\n",
    "    # Calculo dos parametros para uma combinação\n",
    "    # N representa o número de dados para o cálculo da RL\n",
    "    N = d.shape[0]\n",
    "    # X é a matriz dos dados\n",
    "    X = np.hstack([np.ones((N, 1)), combination])\n",
    "    # R é o produto das matrizes X.T e X\n",
    "    R = X.T @ X\n",
    "    # o vetor p é dado pelo produto entre a matriz X.T e o vetor d\n",
    "    p = X.T @ d\n",
    "    # Calcule a solução wo e o erro e\n",
    "\n",
    "    #print(type(R[0,0]))\n",
    "\n",
    "    #R = R.astype('float64')\n",
    "    #p = p.astype('float64')\n",
    "    \n",
    "    wo = np.linalg.solve(R, p)\n",
    "    e = d - X @ wo\n",
    "\n",
    "    # Calculo da \"previsão\" utilizando o modelo\n",
    "    # N representa o número de dados para o cálculo da RL\n",
    "    N_teste = d_teste.shape[0]\n",
    "    # X é a matriz dos dados\n",
    "    X_teste = np.hstack([np.ones((N_teste, 1)), combination_teste])\n",
    "    # previsoes e erros\n",
    "    previsto = []\n",
    "    erro = []\n",
    "    accuracy = []\n",
    "    # para cada linha do conjunto de teste\n",
    "\n",
    "    for i in range(N_teste):\n",
    "        # extrai as features da linha i\n",
    "        xTeste_i = X_teste[i, :]\n",
    "        # calcula o valor predito pelo modelo\n",
    "        y_pred_i = xTeste_i @ wo\n",
    "        # calcula o erro em relação ao valor real\n",
    "        e_i = d_teste[i] - y_pred_i\n",
    "        # salva nos vetores\n",
    "        previsto.append(y_pred_i)\n",
    "        erro.append(e_i)\n",
    "        # imprime o valor predito, o valor real e o erro\n",
    "        # print(f\"Valor predito: {y_pred_i}, Valor real: {dTeste[i]}, Erro: {e_i}\")\n",
    "    # erro da combinacao\n",
    "    mse = np.sqrt(np.mean(np.array(erro)**2))\n",
    "    return mse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função feita, podemos começar a trabalhar em cima dos DataFrames. Precisamos:\n",
    "\n",
    "1. Importar os dataframes de treino e de teste (arquivos csv)\n",
    "2. Substituir cada variável categórica de sua seleção por um conjunto de variáveis dummy, conforme descrito anteriormente.\n",
    "3. Transformar as variáveis originais de sua seleção e / ou incluir combinações, caso julgue necessário;\n",
    "4. A partir de sua seleção de dados, obter a matriz X e o vetor d, que podem ser representados como arrays do NumPy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegando apenas N-1 variáveis Dummy. (N = Quantidade de categorias)\n",
    "\n",
    "A função \"pd.get_dummies\" retorna todas as possíveis variáveis dummy. Contudo, precisamos de apenas N-1 variáveis dummy para cada variável categórica, já que consequentemente uma das categorias pode ser inferida como combinação linear das outras e, portanto, caso incluida no código, pode aumentar o tempo de execução de forma desnecessária:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzindo a quantidade de variaveis dummy em 1 conforme enunciado.\n",
    "# Configurando o \"indice\" das colunas do dataframe\n",
    "condition = [0,1,2,3,4] \n",
    "cylinders = [6]\n",
    "fuel = [8]\n",
    "transmission = [10]\n",
    "size = [12,13,14]\n",
    "carType = [16,17,18]\n",
    "fabrication = [20]\n",
    "odometer = [21]\n",
    "age = [22] #Criamos\n",
    "mileage_per_year = [23] #Criamos\n",
    "\n",
    "# Vetor com todas as colunas possiveis no DataFrame organizadas por tipo\n",
    "avaliabelVariablesIndexes = [condition,cylinders,fuel,transmission,size,carType,fabrication,odometer,age,mileage_per_year]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar-mos o melhor modelo de regressão linear possível, queremos tentar todas as combinações possíveis entre as variáveis que possuimos, avaliar cada modelo pelo erro quadrático e então em tese encontraremos o melhor modelo possível com nossas variáveis escolhidas.\n",
    "\n",
    "Para isso vamos primeiro criar todas as permutações possíveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando todas as permutações possíveis entre as colunas do DataFrame\n",
    "combinations = [] # É uma lista cujo i-ésimo elemento guarda os indices das colunas referentes a uma possível permutação\n",
    "for i in range(2, len(avaliabelVariablesIndexes) + 1):\n",
    "    for subset in itertools.combinations(avaliabelVariablesIndexes, i):\n",
    "        combinations.append(list(itertools.chain.from_iterable(subset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criado o vetor de combinações, podemos agora fazer a regressão linear para cada uma delas e encontrar o menor erro entre todos os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando a regressão linear para cada uma das combinações possíveis\n",
    "# Salvamos apenas quando uma regressão possui uma resposta 'melhor' que uma anterior\n",
    "\n",
    "#d_train = d_train.to_frame()\n",
    "#d_test = d_test.to_frame()\n",
    "\n",
    "min_mse = np.inf\n",
    "for i in range(len(combinations)-1):\n",
    "    try:\n",
    "        print(i)\n",
    "        mse = RL(d_train, d_test, X_train.iloc[:, combinations[i]], X_test.iloc[:, combinations[i]])\n",
    "        if mse < min_mse:\n",
    "            print(\"Erro:\", mse, \"Feature Combo:\", combinations[i])\n",
    "            min_mse = mse\n",
    "            combo_number = i\n",
    "            best_features = list(combinations[i])\n",
    "    except np.linalg.LinAlgError:\n",
    "        continue\n",
    "\n",
    "# Print do melhor resultado\n",
    "print(\"Best feature combination: \", best_features)\n",
    "print(\"Best feature number:\", combo_number)\n",
    "print(\"Minimum MSE: \", min_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "794011319cd091dc0c66d4aa7874d3fb42f19e47c0e5a47abafd0a437ebb9c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
